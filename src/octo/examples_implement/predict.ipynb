{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rospy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrospy\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'rospy'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"Kuavo机器人基础手臂位置控制案例展示\n",
    "\n",
    "这个案例演示了如何使用ACT进行后续机器人动作的执行\n",
    "\n",
    "功能描述：\n",
    "- 初始化ROS节点\n",
    "- 初始化Kuavo机器人实例\n",
    "- 发布手臂关节数据，控制手臂运动到指定位置\n",
    "- 关闭手臂控制\n",
    "\"\"\"\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import rospy\n",
    "import time\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "from typing import List\n",
    "from kuavoRobotSDK import kuavo\n",
    "from dynamic_biped.msg import robotArmInfo\n",
    "from dynamic_biped.msg import robotArmQVVD\n",
    "from dynamic_biped.srv import controlEndHand, controlEndHandRequest\n",
    "from sensor_msgs.msg import JointState\n",
    "from camera_init import camera_init, camera_main, camera_close\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "pipeline = camera_init()\n",
    "\n",
    "status = False\n",
    "\n",
    "\n",
    "\"\"\"功能函数\"\"\"\n",
    "\n",
    "class Human_ACT(object):\n",
    "\n",
    "    def __init__(self, state:int, count:int ):\n",
    "\n",
    "        print(\"当前开始人形机器人的模仿学习操作\")\n",
    "\n",
    "        self.joint_position_right = [0] * state\n",
    "        self.joint_position = [0] * count\n",
    "        self.robot_instance = kuavo(\"3_7_kuavo\")\n",
    "        self.image = None\n",
    "        self.num = 1\n",
    "\n",
    "    def rad_to_angle(self, rad_list: list) -> list:\n",
    "        \"\"\"弧度转变为角度\"\"\"\n",
    "        angle_list = [0 for _ in range(len(rad_list))]\n",
    "        for i, rad in enumerate(rad_list):\n",
    "            angle_list[i] = rad / math.pi * 180.0\n",
    "        return angle_list\n",
    "\n",
    "    def get_RobotState_callback(self, msg):\n",
    "        \"\"\"获取机器人本体的相关数据信息\"\"\"\n",
    "\n",
    "        global status\n",
    "\n",
    "        state_Q = self.rad_to_angle(msg.q)\n",
    "\n",
    "        if status is True:\n",
    "\n",
    "            if self.num == 1:\n",
    "\n",
    "                self.depth, self.image = camera_main(pipeline=pipeline)\n",
    "\n",
    "                # 到达某个初始位置\n",
    "\n",
    "                self.joint_position[7:14] = [1.5644865540106576, -5.433135139667643, -39.900632294200555, 0.0, -12.607800276665358, 3.0374787484520107, 4.324829964010405]\n",
    "\n",
    "            else:\n",
    "\n",
    "                status = False\n",
    "\n",
    "                # 从当前的视频流里边记录图片的数值\n",
    "                self.depth, self.image = copy.deepcopy(camera_main(pipeline=pipeline))\n",
    "\n",
    "                # 将左胳膊的值记录下来作为运行时候的值\n",
    "                self.joint_position[0:7] = copy.deepcopy(state_Q[0:7])\n",
    "\n",
    "                # 用右胳膊做预测，所以提取的值是拿到的7到14\n",
    "                self.joint_position_right[0:7] = copy.deepcopy(state_Q[7:14])\n",
    "\n",
    "                print(\"执行一次之后阻塞住，然后去进行ACT的运动，此时joint_position,joint_position_right值是固定好的\")\n",
    "\n",
    "\n",
    "    def pub_kuavo_arm_traj(self, joint_position: list):\n",
    "\n",
    "        try:\n",
    "            arm_traj_msg = JointState()\n",
    "\n",
    "            joint_position = self.judgement_joint(joint_position = joint_position)\n",
    "\n",
    "            arm_traj_msg.position = joint_position\n",
    "\n",
    "            # print(arm_traj_msg.position, \"^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\")\n",
    "\n",
    "            self.arm_traj_pub.publish(arm_traj_msg)\n",
    "            return True\n",
    "\n",
    "        except Exception as error:\n",
    "            print(error)\n",
    "            return False\n",
    "\n",
    "\n",
    "    def judgement_joint(self, joint_position:list):\n",
    "\n",
    "        # min_lim = [-180, -200, -135, -200, -135, -60, -80, -180, -180, -180, -200, -180, -40, -40]  # 遥操作中读取\n",
    "        min_lim = [-180, -5, -90, -90, -90, -90, -90, -180, -135, -90, -90, -90, -90, -90]  # 手动估计测量\n",
    "\n",
    "        # max_lim = [30, 135, 135, 0, 135, 60, 80, 180, 180, 180, 0, 180, 40, 40]  # 遥操作中读取\n",
    "        max_lim = [30, 135, 90, 0, 90, 90, 90,  30, 5,  90, 0, 90, 90, 90]  # 手动估计测量\n",
    "\n",
    "        for i in range(len(joint_position)):\n",
    "\n",
    "            if joint_position[i] < min_lim[i]:\n",
    "                joint_position[i] = min_lim[i]\n",
    "\n",
    "            if joint_position[i] > max_lim[i]:\n",
    "                joint_position[i] = max_lim[i]\n",
    "\n",
    "        return joint_position\n",
    "\n",
    "    def call_control_end_hand_service(self, left_hand_position: List[float], right_hand_position: List[float]):\n",
    "\n",
    "        \"\"\"控制爪子开合的服务\"\"\"\n",
    "        hand_positions = controlEndHandRequest()\n",
    "        hand_positions.left_hand_position = left_hand_position  # 左手位置\n",
    "        hand_positions.right_hand_position = right_hand_position  # 右手位置\n",
    "\n",
    "        try:\n",
    "            rospy.wait_for_service('/control_end_hand')\n",
    "            control_end_hand = rospy.ServiceProxy('/control_end_hand', controlEndHand)\n",
    "            resp = control_end_hand(hand_positions)\n",
    "            return resp.result\n",
    "\n",
    "        except rospy.ROSException as e:\n",
    "\n",
    "            rospy.logerr(\"Service call failed: %s\" % e)\n",
    "            return False\n",
    "\n",
    "    def control_end_hand(self, hand_status):\n",
    "        \"\"\"控制夹爪开合的函数，0表示关，1表示开\"\"\"\n",
    "\n",
    "        if hand_status == 0:\n",
    "            left_hand_position = [0, 0, 0, 0, 0, 0]\n",
    "            right_hand_position = [0, 70, 20, 20, 20, 20]\n",
    "\n",
    "        elif hand_status == 1:\n",
    "            left_hand_position = [0, 0, 0, 0, 0, 0]\n",
    "            right_hand_position = [0, 30, 80, 80, 80, 80]\n",
    "\n",
    "        else:\n",
    "            print(\"输入错误，请重新输入\")\n",
    "\n",
    "        success = self.call_control_end_hand_service(left_hand_position, right_hand_position)\n",
    "\n",
    "        if success:\n",
    "            rospy.loginfo(\"Hand control service call successful.\")\n",
    "        else:\n",
    "            rospy.loginfo(\"Hand control service call failed.\")\n",
    "\n",
    "    def My_ACT(self,model):\n",
    "        import jax\n",
    "\n",
    "        print('self.joint_position_right',self.joint_position_right)\n",
    "        input_image02 = np.stack(np.array(self.image)[None])\n",
    "        input_state=np.stack(np.array(self.joint_position_right)[None])\n",
    "        observation = {\n",
    "            'proprio':input_state,\n",
    "            'image_primary': input_image02,\n",
    "            # 'image_wrist':input_images01,\n",
    "            'timestep_pad_mask': np.full((1, input_image02.shape[1]), True, dtype=bool)\n",
    "        }\n",
    "        language_instruction = \"put the bottle in the box\"\n",
    "        task = model.create_tasks(texts=[language_instruction])                  # for language conditioned\n",
    "        actions = model.sample_actions(\n",
    "            observation, \n",
    "            task, \n",
    "            unnormalization_statistics=model.dataset_statistics[\"action\"], \n",
    "            rng=jax.random.PRNGKey(0)\n",
    "        )\n",
    "        action = actions[0][0]\n",
    "        print(action)\n",
    "        # global status\n",
    "        # # global num\n",
    "\n",
    "        # status = True\n",
    "\n",
    "        # if self.image is not None:\n",
    "\n",
    "        #     if self.num == 1:\n",
    "\n",
    "        #         print(\"当前是初始化函数，只执行一次\")\n",
    "        #         res = self.pub_kuavo_arm_traj(self.joint_position)\n",
    "        #         time.sleep(0.5)\n",
    "        #         self.num += 1\n",
    "\n",
    "        #     else:\n",
    "\n",
    "        #         camera_image = self.image\n",
    "\n",
    "        #         right_list = self.joint_position_right\n",
    "\n",
    "        #         #print(\"^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\", right_list)\n",
    "\n",
    "        #         target_right_list = main_ACT(cam_followed=camera_image, current_joints=right_list)\n",
    "\n",
    "        #         # 将本次预测出来的夹爪值赋值给下一个的夹爪值\n",
    "        #         self.joint_position_right[7] = np.around(target_right_list[7])\n",
    "\n",
    "        #         print( target_right_list[7],\"^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\")\n",
    "                \n",
    "\n",
    "        #         # 14维度，将预测出来的7个维度拼到joint_position上\n",
    "        #         self.joint_position[7:14] = copy.deepcopy(target_right_list[0:7])\n",
    "        #         print(self.joint_position,\"**************************************************\")\n",
    "\n",
    "        #         res = self.pub_kuavo_arm_traj(self.joint_position)\n",
    "        #         # if np.around(target_right_list[7]) == 1.0 and self.num > 50:\n",
    "        #         # if target_right_list[7] > 1:\n",
    "\n",
    "        #         #     time.sleep(0.5)\n",
    "        #         #     self.call_control_end_hand_service(left_hand_position=[0, 0, 0, 0, 0, 0], right_hand_position=[0, 30, 80, 80, 80, 80])\n",
    "\n",
    "        #         # else:\n",
    "        #         #     self.call_control_end_hand_service(left_hand_position=[0, 0, 0, 0, 0, 0], right_hand_position=[0, 70, 20, 20, 20, 20])\n",
    "\n",
    "        #         self.num = self.num + 1\n",
    "\n",
    "\n",
    "    def my_main(self):\n",
    "        \n",
    "        rospy.init_node('demo_test')\n",
    "\n",
    "        self.arm_traj_pub  = rospy.Publisher(\"/kuavo_arm_traj\", JointState, queue_size=10)\n",
    "\n",
    "        self.arm_traj_pub_ = rospy.Subscriber(\"/robot_arm_q_v_tau\", robotArmInfo, self.get_RobotState_callback)\n",
    "        # self.arm_traj_pub_ = rospy.Subscriber(\"/robot_arm_q_v_tau\", robotArmQVVD, self.get_RobotState_callback)\n",
    "\n",
    "        # from octo.model.octo_model import OctoModel\n",
    "        # checkpoint_path = \"/home/rebot801/LIuXin/ICCUB_ws/src/octo/scripts/finetune_ckpt/octo_finetune/experiment_20240715_100826\"\n",
    "        # step = 8000\n",
    "        # model_1cam_5eps_s2c=OctoModel.load_pretrained(checkpoint_path,step)\n",
    "        # model=model_1cam_5eps_s2c\n",
    "        \n",
    "        while not rospy.is_shutdown():\n",
    "\n",
    "            # self.My_ACT(model)\n",
    "            time.sleep(0.5)\n",
    "\n",
    "        camera_close(pipeline=pipeline)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 初始化节点\n",
    "    kuavo = Human_ACT(state=8, count=14)\n",
    "\n",
    "    kuavo.my_main()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "octo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
