I0709 08:44:52.140000 140319875794112 checkpointer.py:166] Finished restoring checkpoint from /home/rebot801/hx/dc9aa3019f764726c770814b27e4ab0fc6e32a58/300000/default.
I0709 08:44:54.893094 140319875794112 dataset_info.py:578] Load dataset info from data/z1/1.0.0
I0709 08:44:54.967722 140319875794112 logging_logger.py:49] Constructing tf.data.Dataset z1 for split all, from data/z1/1.0.0
WARNING:tensorflow:AutoGraph could not transform <function _gcd_import at 0x7f9ec3c93400> and will run it as-is.
Cause: Unable to locate the source code of <function _gcd_import at 0x7f9ec3c93400>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
W0709 08:44:55.737479 140319875794112 ag_logging.py:142] AutoGraph could not transform <function _gcd_import at 0x7f9ec3c93400> and will run it as-is.
Cause: Unable to locate the source code of <function _gcd_import at 0x7f9ec3c93400>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
I0709 08:44:56.878700 140319875794112 api.py:446] Sampling uniformly across keys: ['language_instruction']
I0709 08:44:57.221667 140319875794112 data_utils.py:113] Loading existing dataset statistics from data/z1/1.0.0/dataset_statistics_d70d77f999966076ad55617e5e36e72ab25e6009f1c3bbc7047f250be38268d0.json.
I0709 08:44:57.260943 140319875794112 logging_logger.py:49] Constructing tf.data.Dataset z1 for split train, from data/z1/1.0.0
I0709 08:44:57.382009 140319875794112 api.py:446] Sampling uniformly across keys: ['language_instruction']
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
W0000 00:00:1720485912.550089   92941 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 256 } dim { size: 256 } dim { size: -6 } } } inputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -2 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "103" frequency: 3417 num_cores: 24 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 31457280 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: -12 } dim { size: -13 } dim { size: -6 } } }
W0000 00:00:1720485912.550607   92941 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: "CropAndResize" attr { key: "T" value { type: DT_FLOAT } } attr { key: "extrapolation_value" value { f: 0 } } attr { key: "method" value { s: "bilinear" } } inputs { dtype: DT_FLOAT shape { dim { size: 1 } dim { size: 256 } dim { size: 256 } dim { size: -7 } } } inputs { dtype: DT_FLOAT shape { dim { size: -4 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -4 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: "CPU" vendor: "GenuineIntel" model: "103" frequency: 3417 num_cores: 24 environment { key: "cpu_instruction_set" value: "AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2" } environment { key: "eigen" value: "3.4.90" } l1_cache_size: 49152 l2_cache_size: 2097152 l3_cache_size: 31457280 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -4 } dim { size: -17 } dim { size: -18 } dim { size: -7 } } }